a <- c(1, 2, 3, 4, "abc")
typeof(a)
a
a <- c(1, 2, 3, 4, 5)
a
typeof(a)
true
TRUE
a[1]
a[c(1, 2)]
rep("abc", 5)
typeof(rep('ab', 5))
gender <- c(rep("male", 10), rep("female", 20))
gender
gender <- factor(gender)
gender
typeof(gender)
summary(gender)
rm(list=ls(all=TRUE))
x <- (rexp(10000, rate=.1), ncol=100)
matrix(rexp(200, rate=.1), ncol=20)
x <- matrix(rexp(10000, rate=.1), ncol=100)
dim(x)
help rnorm
hel(rnorm)
help(rnorm)
g <- rnorm(10000)
dim(g)
length(g)
remove(g)
ptm <- proc.time()
fit <- kmeans(x, 5)
proc.time() - ptm
x <- matrix(rexp(100000, rate=.1), ncol=100)
ptm <- proc.time()
fit <- kmeans(x, 5)
proc.time() - ptm
x <- matrix(rexp(10000000, rate=.1), ncol=100)
ptm <- proc.time()
fit <- kmeans(x, 5)
proc.time() - ptm
dim(x)
kmeans(x, 5)
x <- matrix(rexp(10000000, rate=.1), ncol=100)
ptm <- proc.time()
fit <- kmeans(x, 5)
proc.time() - ptm
setwd('Documents/ML/Assignment3/p7')
a <- NULL
a <- a + matrix(seq_len(9), ncol=3)
a <- matrix(0, 3, 3)
a
source('~/Documents/ML/Assignment3/p7/FDA.R')
suppressMessages(library(R.matlab))
suppressMessages(library(Brobdingnag))
suppressMessages(library(CMA))
source('ComputeDataLikelihoods.R')
source('LikelihoodProbability.R')
source('Predict.R')
source('FDA.R')
data <- readMat('../datasets/mnist_all.mat')
# Sample and partition data into training and testing data
train.data <- NULL
test.data <- NULL
for(i in 1:10) {
# Combine previous training and testing data
temp <- data.frame(matrix(c(data[2*(i-1) + 1][[1]], data[2*i][[1]]), ncol=784))
temp <- temp[sample(1:nrow(temp), 200), ]
temp <- cbind(temp, rep(i-1, nrow(temp))) # Add class label as the last field
train <- sample(1:nrow(temp), nrow(temp)/2)
test <- -train
train.data <- rbind(train.data, temp[train, ])
test.data <- rbind(test.data, temp[test, ])
}
rm(data, temp, test, train) # Remove unnecessary variables
FDA(test.data)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
a
colMeans()
colMeans(a)
dim(colMeans(a))
b <- (colMeans(a))
b
typeof(b)
dim(b)
size(b)
t(b)
dim(t(b))
b %*% t(b)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
help(inv)
help(solve)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
library(MASS)
help(ginv)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
source('~/Documents/ML/Assignment3/p7/FDA.R')
FDA(test.data)
source('~/Documents/ML/Assignment3/p7/FDA.R')
eig <- FDA(test.data)
names(eig$values)
colnames(eig$values)
names(eig$val)
colnames(eig$val)
typeof(eig$val)
eig$val
a <- princomp(test.data[, 1:784])
a
summary(a)
a$scores
help(princomp)
a$sdev
a$sdev > 0
which(a$sdev > 0)
length(a$sdev > 0)
which(a$sdev > 0)
b <-which(a$sdev > 0)
length(b)
length(which(a$sdev > 0))
# Take FDA projection onto 9 dims, after removing singularity
nonzero_var <- length(which(train.pca$dev > 0))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
train.pca <- princomp(train.data[, 1:784], scores=TRUE)
nonzero_var <- length(which(train.pca$dev > 0))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
eig <- FDA(train.proj)
nonzero_var
train.pca$sdev > 0
nonzero_var <- length(which(train.pca$sdev > 0))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
eig <- FDA(train.proj)
source('~/Documents/ML/Assignment3/p7/FDA.R')
eig <- FDA(train.proj)
eig$val
help(order)
order(eig$val)
dim(eig$val)
length(eig$val)
typeof(eig$val)
dim(train.proj)
x = 4 + 5i
y = 4 + 6i
x > y
help(eigen)
eig$values
eig$vectors[1, ]
values <- eig$val[1:9]
values
as.double(vlaues)
as.double(values)
vectors <- eig$vectors[, 1:9]
vectors[, 1]
as.double(vectors)
help(stop)
source('~/Documents/ML/Assignment3/p7/FDA.R')
eig <- FDA(train.proj, comp=10)
eig <- FDA(train.proj, comp=1000)
source('~/Documents/ML/Assignment3/p7/FDA.R')
eig <- FDA(train.proj, comp=1000)
source('~/Documents/ML/Assignment3/p7/FDA.R')
eig <- FDA(train.proj, comp=9)
fda <- FDA(train.proj, comp=9)
source('~/Documents/ML/Assignment3/p7/FDA.R')
train.fda <- FDA(train.proj, comp=9)
dim(train.fda)
source('~/Documents/ML/Assignment3/p7/FDA.R')
dim(train.fda)
train.fda <- FDA(train.proj, comp=9)
dim(train.fda)
train.fda
dim(train.fda)
as.matrix(train.fda)
double(train.fda)
as.double(train.fda)
as.matrix(as.double(train.fda))
train.data
dim(train.data)
dim(train.fda)
data.frame(train.fda)
train.fda
train.fda[1, ]
a <- as.double(train.fda[1, ])
a
b<-as.matrix(as.double(train.fda), nrow=9)[1, ]
b
as.matrix(as.double(train.fda), nrow=9)
matrix(as.double(train.fda), nrow=9)
b<-matrix(as.double(train.fda), nrow=9)
b
a
a == b
a
b
b<-matrix(as.double(train.fda), nrow=9, byrow=T)
b[1, ]
b<-matrix(as.double(train.fda), nrow=9)
b[1, ]
a
a == b[1, ]
source('~/Documents/ML/Assignment3/p7/FDA.R')
train.fda <- FDA(train.proj, comp=9)
dim(train.fda)
train.fda
dim(train.data)
dim(train.proj)
train.fda <- FDA(train.proj, comp=9)
train.proj <- train.proj %*% t(train.fda)
typeof(train.proj)
typeof(train.fda)
dim(train.proj)
dim(train.fda)
train.fda <- FDA(train.proj, comp=9)
train.proj <- train.proj[, 1:nonzero_var] %*% t(train.fda)
train.proj <- cbind(train.proj, train.data[, 785])
test.proj <- test.proj[, 1:nonzero_var] %*% t(train.fda)
test.proj <- cbin(test.proj, test.data[, 785])
test.proj <- cbind(test.proj, test.data[, 785])
train.likelihood <- ComputeDataLikelihoods(train.proj)
test.accuracy <- Predict(train.likelihood, test.proj, c(0:9))
cat("Accuracy on test using FDA: ", test.accuracy)
dim(train.proj)
dim(test.proj)
train.fda <- FDA(train.proj, comp=9)
nonzero_var <- length(which(train.pca$sdev > 0))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
train.fda <- FDA(train.proj, comp=9)
train.proj <- train.proj[, 1:nonzero_var] %*% t(train.fda)
train.proj <- cbind(train.proj, train.data[, 785])
test.proj <- test.proj[, 1:nonzero_var] %*% t(test.fda)
test.proj <- cbind(test.proj, test.data[, 785])
test.proj <- test.proj[, 1:nonzero_var] %*% t(train.fda)
test.proj <- cbind(test.proj, test.data[, 785])
train.likelihood <- ComputeDataLikelihoods(train.proj)
test.accuracy <- Predict(train.likelihood, test.proj, c(0:9))
cat("Accuracy on test using FDA: ", test.accuracy)
help(eigen)
a
source('~/Documents/ML/Assignment3/p7/FDA.R')
train.fda <- FDA(train.proj, comp=9)
# Take FDA projection onto 9 dims, after removing singularity. Train and classsify.
nonzero_var <- length(which(train.pca$sdev > 0))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
train.fda <- FDA(train.proj, comp=9)
source('~/Documents/ML/Assignment3/p7/FDA.R')
a <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9), ncol=3)
a
eig <- eigen(a)
eig$val
t(a)
dim(train.proj)
# Take FDA projection onto 9 dims, after removing singularity. Train and classsify.
nonzero_var <- length(which(train.pca$sdev > 0))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
train.fda <- FDA(train.proj, comp=9)
train.proj <- train.proj[, 1:nonzero_var] %*% train.fda
train.proj <- cbind(train.proj, train.data[, 785])
test.proj <- test.proj[, 1:nonzero_var] %*% train.fda
test.proj <- cbind(test.proj, test.data[, 785])
dim(train.fda)
dim(train.proj)
# Take FDA projection onto 9 dims, after removing singularity. Train and classsify.
nonzero_var <- length(which(train.pca$sdev > 0))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
train.fda <- FDA(train.proj, comp=9)
dim(train.proj)
dim(train.fda)
source('~/Documents/ML/Assignment3/p7/FDA.R')
# Take FDA projection onto 9 dims, after removing singularity. Train and classsify.
nonzero_var <- length(which(train.pca$sdev > 0))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
train.fda <- FDA(train.proj, comp=9)
train.proj <- train.proj[, 1:nonzero_var] %*% train.fda
train.proj <- cbind(train.proj, train.data[, 785])
test.proj <- test.proj[, 1:nonzero_var] %*% train.fda
test.proj <- cbind(test.proj, test.data[, 785])
train.likelihood <- ComputeDataLikelihoods(train.proj)
test.accuracy <- Predict(train.likelihood, test.proj, c(0:9))
cat("Accuracy on test using FDA: ", test.accuracy)
help(lda)
# Take FDA projection onto 9 dims, after removing singularity. Train and classsify.
nonzero_var <- length(which(train.pca$sdev > 0))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
train.fda <- fdaCMA(train.proj[, 1:nonzero_var], train.data[, 785], comp=9)
dim(train.proj)
typeof(tran.proj)
typeof(train.proj)
train.fda <- fdaCMA(train.proj[, 1:nonzero_var], factor(train.data[, 785]), comp=9)
train.fda <- fdaCMA(train.proj[, 1:20], factor(train.data[, 785]), comp=9)
train.fda <- fdaCMA(train.proj[, 1:500], factor(train.data[, 785]), comp=9)
test.proj <- cbind(test.proj[, 1:9], test.data[, 785])
train.fda <- fdaCMA(train.proj[, 1:700], factor(train.data[, 785]), comp=9)
train.fda <- fdaCMA(train.proj[, 1:600], factor(train.data[, 785]), comp=9)
train.fda <- fdaCMA(train.proj[, 1:650], factor(train.data[, 785]), comp=9)
train.fda <- fdaCMA(train.proj[, 1:690], factor(train.data[, 785]), comp=9)
train.fda <- fdaCMA(train.proj[, 1:680], factor(train.data[, 785]), comp=9)
train.fda <- fdaCMA(train.proj[, 1:670], factor(train.data[, 785]), comp=9)
train.fda <- fdaCMA(train.proj[, 1:660], factor(train.data[, 785]), comp=9)
train.fda <- fdaCMA(train.proj[, 1:650], factor(train.data[, 785]), comp=9)
train.pca$sdev
# Take FDA projection onto 9 dims, after removing singularity. Train and classsify.
nonzero_var <- length(which(train.pca$sdev > 1))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
train.fda <- fdaCMA(train.proj[, 1:nonzero_var], factor(train.data[, 785]), comp=9)
predict(train.fda, test.proj[, 1:nonzer_var])
summary(train.fda)
train.fda
show(train.fda)
ftable(train.fda)
# Take FDA projection onto 9 dims, after removing singularity. Train and classsify.
nonzero_var <- length(which(train.pca$sdev > 1))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
train.fda <- fdaCMA(train.proj[, 1:nonzero_var], factor(train.data[, 785]), comp=9, models=TRUE)
train.fda
summary(train.fda)
names(train.fda)
train.fda$scores
train.fda
ftable(train.fda)
help(cancor)
nonzero_var <- length(which(train.pca$sdev > 1))
train.proj <- cbind(train.pca$scores[, 1:nonzero_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:nonzero_var], test.data[, 785])
train.fda <- FDA(train.proj, comp=9)
train.proj <- train.proj[, 1:nonzero_var] %*% train.fda
train.proj <- cbind(train.proj, train.data[, 785])
test.proj <- test.proj[, 1:nonzero_var] %*% train.fda
test.proj <- cbind(test.proj, test.data[, 785])
train.likelihood <- ComputeDataLikelihoods(train.proj)
test.accuracy <- Predict(train.likelihood, test.proj, c(0:9))
cat("Accuracy on test using FDA: ", test.accuracy)
suppressMessages(library(R.matlab))
suppressMessages(library(Brobdingnag))
suppressMessages(library(CMA))
source('ComputeDataLikelihoods.R')
source('LikelihoodProbability.R')
source('Predict.R')
source('FDA.R')
data <- readMat('../datasets/mnist_all.mat')
# Sample and partition data into training and testing data
train.data <- NULL
test.data <- NULL
for(i in 1:10) {
# Combine previous training and testing data
temp <- data.frame(matrix(c(data[2*(i-1) + 1][[1]], data[2*i][[1]]), ncol=784))
temp <- temp[sample(1:nrow(temp), 200), ]
temp <- cbind(temp, rep(i-1, nrow(temp))) # Add class label as the last field
train <- sample(1:nrow(temp), nrow(temp)/2)
test <- -train
train.data <- rbind(train.data, temp[train, ])
test.data <- rbind(test.data, temp[test, ])
}
rm(data, temp, test, train) # Remove unnecessary variables
# Scale training and testing data
#train.data <- scale(train.data, center=FALSE, scale=TRUE)
#test.data <- scale(test.data, center=FALSE, scale=TRUE)
# Take PCA projection onto top 9 dims. Train and classify.
train.pca <- princomp(train.data[, 1:784], scores=TRUE)
test.proj <- predict(train.pca, test.data[, 1:784])
train.proj <- cbind(train.pca$scores[, 1:9], train.data[, 785])
test.proj <- cbind(test.proj[, 1:9], test.data[, 785])
train.likelihood <- ComputeDataLikelihoods(train.proj)
test.accuracy <- Predict(train.likelihood, test.proj, c(0:9))
cat("Accuracy on test data using PCA: ", test.accuracy)
# Take FDA projection onto 9 dims, after removing singularity. Train and classsify.
high_var <- length(which(train.pca$sdev > 1))
train.proj <- cbind(train.pca$scores[, 1:high_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:high_var], test.data[, 785])
train.fda <- FDA(train.proj, comp=9)
train.proj <- train.proj[, 1:high_var] %*% train.fda
train.proj <- cbind(train.proj, train.data[, 785])
test.proj <- test.proj[, 1:high_var] %*% train.fda
test.proj <- cbind(test.proj, test.data[, 785])
train.likelihood <- ComputeDataLikelihoods(train.proj)
test.accuracy <- Predict(train.likelihood, test.proj, c(0:9))
cat("Accuracy on test using FDA: ", test.accuracy)
suppressMessages(library(R.matlab))
suppressMessages(library(Brobdingnag))
suppressMessages(library(CMA))
source('ComputeDataLikelihoods.R')
source('LikelihoodProbability.R')
source('Predict.R')
source('FDA.R')
data <- readMat('../datasets/mnist_all.mat')
# Sample and partition data into training and testing data
train.data <- NULL
test.data <- NULL
for(i in 1:10) {
# Combine previous training and testing data
temp <- data.frame(matrix(c(data[2*(i-1) + 1][[1]], data[2*i][[1]]), ncol=784))
temp <- temp[sample(1:nrow(temp), 200), ]
temp <- cbind(temp, rep(i-1, nrow(temp))) # Add class label as the last field
train <- sample(1:nrow(temp), nrow(temp)/2)
test <- -train
train.data <- rbind(train.data, temp[train, ])
test.data <- rbind(test.data, temp[test, ])
}
rm(data, temp, test, train) # Remove unnecessary variables
# Scale training and testing data
#train.data <- scale(train.data, center=FALSE, scale=TRUE)
#test.data <- scale(test.data, center=FALSE, scale=TRUE)
# Take PCA projection onto top 9 dims. Train and classify.
train.pca <- princomp(train.data[, 1:784], scores=TRUE)
test.proj <- predict(train.pca, test.data[, 1:784])
train.proj <- cbind(train.pca$scores[, 1:9], train.data[, 785])
test.proj <- cbind(test.proj[, 1:9], test.data[, 785])
train.likelihood <- ComputeDataLikelihoods(train.proj)
test.accuracy <- Predict(train.likelihood, test.proj, c(0:9))
cat("Accuracy on test data using PCA: ", test.accuracy)
# Take FDA projection onto 9 dims, after removing singularity. Train and classsify.
high_var <- length(which(train.pca$sdev > 1))
train.proj <- cbind(train.pca$scores[, 1:high_var], train.data[, 785])
test.proj <- predict(train.pca, test.data[, 1:784])
test.proj <- cbind(test.proj[, 1:high_var], test.data[, 785])
train.fda <- FDA(train.proj, comp=9)
train.proj <- train.proj[, 1:high_var] %*% train.fda
train.proj <- cbind(train.proj, train.data[, 785])
test.proj <- test.proj[, 1:high_var] %*% train.fda
test.proj <- cbind(test.proj, test.data[, 785])
train.likelihood <- ComputeDataLikelihoods(train.proj)
test.accuracy <- Predict(train.likelihood, test.proj, c(0:9))
cat("Accuracy on test using FDA: ", test.accuracy)
